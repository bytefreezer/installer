# ByteFreezer Proxy Helm Chart Values
# Edge data collection and forwarding to receiver

# Receiver configuration
receiver:
  # URL of the ByteFreezer receiver webhook endpoint
  url: "https://receiver.bytefreezer.com"  # e.g., https://receiver.example.com:8080

# Control Service configuration
controlService:
  url: "https://api.bytefreezer.com"  # e.g., https://api.bytefreezer.com
  # Account ID - the proxy polls Control for all tenants + datasets for this account
  accountId: "3dzauc5dmov6"  # Required: e.g., "ejq73vgnw26p"
  # Bearer token - account-specific API key for all auth (config polling AND health reporting)
  bearerToken: "9fKiv74S3TrqQ2igBIOb7hWSiVFq3VtzLJo1"  # Required: account API key
  # Use existing secret for bearer token (key: bearerToken)
  existingSecret: ""
  timeoutSeconds: 30

# Replica count
replicaCount: 1

# Image configuration
image:
  repository: ghcr.io/bytefreezer/bytefreezer-proxy
  tag: "latest"
  pullPolicy: IfNotPresent

imagePullSecrets: []

# Service account
serviceAccount:
  create: true
  name: ""
  annotations: {}

# API service (health checks, metrics)
service:
  type: ClusterIP
  apiPort: 8008

# UDP listener configuration
# With hostNetwork, UDP ports are exposed directly on the node - no service needed
udp:
  enabled: false
  ports:
    - port: 5514
      name: syslog
  service:
    type: LoadBalancer
    # MetalLB Configuration (for k3s/bare-metal with MetalLB)
    # Specify a static IP from your MetalLB pool
    loadBalancerIP: ""
    # Service annotations
    annotations:
      metallb.universe.tf/loadBalancerIPs: "192.168.86.139"
      metallb.universe.tf/address-pool: "postgresql-pool"

# Webhook listener (optional)
webhook:
  enabled: false
  port: 8080

# Batching configuration
batching:
  enabled: true
  maxLines: 10000
  maxBytes: 10485760  # 10MB
  timeoutSeconds: 30
  compressionEnabled: true
  compressionLevel: 6

# Spooling configuration (local disk buffer)
spooling:
  enabled: true
  directory: "/var/spool/bytefreezer-proxy"
  maxSizeBytes: 1073741824  # 1GB
  retryAttempts: 3
  retryIntervalSeconds: 60

# Health reporting to control service
healthReporting:
  enabled: true
  reportInterval: 30

# Monitoring/metrics
monitoring:
  enabled: false
  # Mode: "prometheus" (pull), "otlp_http" (push), "otlp_grpc" (push)
  mode: "otlp_http"
  # External endpoint for push modes
  endpoint: "http://otel-collector-opentelemetry-collector.monitoring.svc.cluster.local:4318"
  pushIntervalSeconds: 15
  metricsPort: 9090

# Resource limits
resources:
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 1000m
    memory: 1Gi

# Network mode
# hostNetwork: true  - Pod uses host's network namespace, UDP ports bind directly to node IP
# hostNetwork: false - Pod uses cluster network, use LoadBalancer service for external access
hostNetwork: true

# Pod settings
# nodeName: specify exact node to run on (e.g., "worker-1")
nodeName: "tp5"
nodeSelector: {}
tolerations: []
affinity: {}

# Additional environment variables
extraEnv: []

# Pod security
podSecurityContext:
  fsGroup: 1000

securityContext:
  runAsNonRoot: false
  runAsUser: 0
  readOnlyRootFilesystem: false
  allowPrivilegeEscalation: false
